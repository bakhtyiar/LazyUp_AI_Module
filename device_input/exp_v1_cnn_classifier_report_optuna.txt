C:\Users\bakhtiyar\.conda\envs\myenv\python.exe C:\Users\bakhtiyar\Projects\LazyUp_AI_Module\device_input\experimental_cnn_classifier.py

1. Обучение CNN с оптимизацией гиперпараметров Optuna
[I 2025-05-21 23:44:56,126] A new study created in memory with name: no-name-240fa255-a6e0-4f42-8a40-51395e3c6eab
2025-05-21 23:44:57.922761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2025-05-21 23:44:57.922899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2025-05-21 23:44:57.924154: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[I 2025-05-21 23:45:02,428] Trial 0 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0024420457516779116, 'filters1': 32, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.3289123978821473, 'dropout2': 0.33199404702159363, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:06,493] Trial 1 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0011741165049550235, 'filters1': 128, 'filters2': 64, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.20422650885730853, 'dropout2': 0.2891390450172079, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:10,814] Trial 2 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0002807893275722464, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.3328421928441627, 'dropout2': 0.4899693844105527, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:14,507] Trial 3 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.004404743088173841, 'filters1': 32, 'filters2': 128, 'filters3': 128, 'kernel_size': 5, 'dense1_units': 256, 'dense2_units': 96, 'dropout1': 0.285939120883066, 'dropout2': 0.12048434891188049, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:18,624] Trial 4 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00025938639851953303, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 32, 'dropout1': 0.6088765246548032, 'dropout2': 0.1282225979440872, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:22,686] Trial 5 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0003464852147541841, 'filters1': 128, 'filters2': 128, 'filters3': 384, 'kernel_size': 5, 'dense1_units': 128, 'dense2_units': 96, 'dropout1': 0.4679028525233429, 'dropout2': 0.32672539243984333, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:26,487] Trial 6 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0006043557968184709, 'filters1': 128, 'filters2': 128, 'filters3': 256, 'kernel_size': 7, 'dense1_units': 192, 'dense2_units': 128, 'dropout1': 0.5660135926893233, 'dropout2': 0.10689710050328452, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:30,794] Trial 7 finished with value: 0.6666666865348816 and parameters: {'learning_rate': 0.0015573275077018429, 'filters1': 96, 'filters2': 192, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 128, 'dense2_units': 128, 'dropout1': 0.5340382633169029, 'dropout2': 0.20292499849017182, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:35,173] Trial 8 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.00036092903953511326, 'filters1': 96, 'filters2': 192, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 256, 'dense2_units': 96, 'dropout1': 0.4054834528315896, 'dropout2': 0.11648087576214886, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:39,266] Trial 9 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.006330975832215701, 'filters1': 64, 'filters2': 256, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 64, 'dropout1': 0.23543370238570877, 'dropout2': 0.45869199384568626, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:44,514] Trial 10 finished with value: 0.6666666865348816 and parameters: {'learning_rate': 0.0026338206637239294, 'filters1': 32, 'filters2': 64, 'filters3': 256, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.6876125396333753, 'dropout2': 0.3824644319878526, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:48,934] Trial 11 finished with value: 0.6666666865348816 and parameters: {'learning_rate': 0.0013168787482111426, 'filters1': 32, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 32, 'dropout1': 0.22504850230059664, 'dropout2': 0.2557536999235357, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:52,716] Trial 12 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.002510679818955594, 'filters1': 32, 'filters2': 64, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 192, 'dense2_units': 64, 'dropout1': 0.35327614566737275, 'dropout2': 0.3435860527570229, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:45:57,104] Trial 13 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00012349830431260118, 'filters1': 64, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 32, 'dropout1': 0.2113570040062151, 'dropout2': 0.26486671556308705, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:02,428] Trial 14 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.009417612245798616, 'filters1': 128, 'filters2': 256, 'filters3': 512, 'kernel_size': 7, 'dense1_units': 192, 'dense2_units': 96, 'dropout1': 0.30351851246501665, 'dropout2': 0.4223804425933813, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:06,983] Trial 15 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0007917961455598062, 'filters1': 32, 'filters2': 64, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 32, 'dropout1': 0.39616261218623544, 'dropout2': 0.2113218472826086, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:11,750] Trial 16 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0023069280497517207, 'filters1': 64, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 128, 'dropout1': 0.26775485193570775, 'dropout2': 0.3740121964397142, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:16,083] Trial 17 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.004114213526125134, 'filters1': 96, 'filters2': 64, 'filters3': 256, 'kernel_size': 3, 'dense1_units': 128, 'dense2_units': 64, 'dropout1': 0.4684900878904056, 'dropout2': 0.28983149976976597, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:21,150] Trial 18 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0008471589277223295, 'filters1': 128, 'filters2': 256, 'filters3': 128, 'kernel_size': 5, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.38575344305565856, 'dropout2': 0.2017814602388055, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:26,002] Trial 19 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0014882526728740254, 'filters1': 32, 'filters2': 64, 'filters3': 512, 'kernel_size': 7, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.26332426496065175, 'dropout2': 0.3203596386242889, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:30,723] Trial 20 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0006005271369013319, 'filters1': 128, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.20209687718823502, 'dropout2': 0.40205554547562067, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:35,161] Trial 21 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.00012392614531513398, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.3325880618090772, 'dropout2': 0.4855949074830473, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:39,658] Trial 22 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00023706345817151522, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.32169195246613624, 'dropout2': 0.4905157445560022, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:43,677] Trial 23 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0004963191075901878, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.43756560070760697, 'dropout2': 0.2658275124208493, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:47,657] Trial 24 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0011200603598124483, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.36574382680940765, 'dropout2': 0.43598541490136794, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:51,929] Trial 25 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0019922501942831396, 'filters1': 32, 'filters2': 64, 'filters3': 128, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.25602084390679586, 'dropout2': 0.3555067886646726, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:46:56,133] Trial 26 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.004069835656809774, 'filters1': 96, 'filters2': 192, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 256, 'dense2_units': 128, 'dropout1': 0.30736745692761885, 'dropout2': 0.2357110068210705, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:00,667] Trial 27 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0001961640851437257, 'filters1': 64, 'filters2': 128, 'filters3': 256, 'kernel_size': 3, 'dense1_units': 128, 'dense2_units': 64, 'dropout1': 0.43435561565392183, 'dropout2': 0.15816103309671511, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:05,411] Trial 28 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.000948135571317853, 'filters1': 128, 'filters2': 256, 'filters3': 512, 'kernel_size': 7, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.49833000773534397, 'dropout2': 0.2930055315372885, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:09,316] Trial 29 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.002885427210889416, 'filters1': 32, 'filters2': 128, 'filters3': 128, 'kernel_size': 5, 'dense1_units': 256, 'dense2_units': 96, 'dropout1': 0.2882014906623448, 'dropout2': 0.1613768858243928, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:13,944] Trial 30 finished with value: 0.6666666865348816 and parameters: {'learning_rate': 0.0018816541593395153, 'filters1': 32, 'filters2': 64, 'filters3': 128, 'kernel_size': 5, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.3513001931811471, 'dropout2': 0.46318230272082006, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:18,883] Trial 31 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00022538315726922974, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 32, 'dropout1': 0.6182024865725632, 'dropout2': 0.4207854487871887, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:24,171] Trial 32 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00036334677109073495, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 32, 'dropout1': 0.6221889165168674, 'dropout2': 0.16014819685571846, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:28,556] Trial 33 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0001505237225404837, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 32, 'dropout1': 0.5519044789499462, 'dropout2': 0.13558859230293213, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:33,062] Trial 34 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.00027303712294833777, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 32, 'dropout1': 0.496992075704661, 'dropout2': 0.32206471921052726, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:37,148] Trial 35 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0004907162856551977, 'filters1': 128, 'filters2': 128, 'filters3': 384, 'kernel_size': 7, 'dense1_units': 256, 'dense2_units': 128, 'dropout1': 0.5934470433781962, 'dropout2': 0.18085842919254863, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:40,962] Trial 36 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.00017343454226325305, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 5, 'dense1_units': 128, 'dense2_units': 96, 'dropout1': 0.6852597008915128, 'dropout2': 0.2225744224831792, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:45,069] Trial 37 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0006520037853934292, 'filters1': 96, 'filters2': 192, 'filters3': 256, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 96, 'dropout1': 0.40801179028065404, 'dropout2': 0.10213759311311435, 'batch_size': 32}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:49,299] Trial 38 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.00039517083741456914, 'filters1': 128, 'filters2': 128, 'filters3': 512, 'kernel_size': 7, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.6618620455475512, 'dropout2': 0.3890998290978346, 'batch_size': 64}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:53,104] Trial 39 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0002924937564590511, 'filters1': 64, 'filters2': 64, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 128, 'dense2_units': 64, 'dropout1': 0.5157917240536484, 'dropout2': 0.3580417919610164, 'batch_size': 16}. Best is trial 0 with value: 0.9166666865348816.
[I 2025-05-21 23:47:57,329] Trial 40 finished with value: 1.0 and parameters: {'learning_rate': 0.0001031548076602442, 'filters1': 32, 'filters2': 256, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.47647451076789765, 'dropout2': 0.13307339797123377, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:01,490] Trial 41 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.00015070048827664959, 'filters1': 32, 'filters2': 256, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.469277825390369, 'dropout2': 0.13188801706124978, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:05,357] Trial 42 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0001037512068352784, 'filters1': 32, 'filters2': 256, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.23449591309414683, 'dropout2': 0.13263641615235294, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:10,152] Trial 43 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.003136183066385321, 'filters1': 32, 'filters2': 256, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.4175709073113164, 'dropout2': 0.18599855668817872, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:14,478] Trial 44 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0012958190751426618, 'filters1': 32, 'filters2': 256, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.5885327246350219, 'dropout2': 0.2504946632395541, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:18,273] Trial 45 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.005162046422967767, 'filters1': 32, 'filters2': 64, 'filters3': 384, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.5433751584340077, 'dropout2': 0.11361533319071435, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:22,424] Trial 46 finished with value: 0.9166666865348816 and parameters: {'learning_rate': 0.0004602259442327052, 'filters1': 96, 'filters2': 256, 'filters3': 512, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 128, 'dropout1': 0.37028488731248294, 'dropout2': 0.30841311968362345, 'batch_size': 64}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:26,414] Trial 47 finished with value: 0.6666666865348816 and parameters: {'learning_rate': 0.0006844651750746757, 'filters1': 32, 'filters2': 64, 'filters3': 256, 'kernel_size': 3, 'dense1_units': 256, 'dense2_units': 96, 'dropout1': 0.33465910726366127, 'dropout2': 0.2729326704445501, 'batch_size': 16}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:30,133] Trial 48 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0001022455466251106, 'filters1': 128, 'filters2': 64, 'filters3': 512, 'kernel_size': 3, 'dense1_units': 192, 'dense2_units': 32, 'dropout1': 0.2941436718310359, 'dropout2': 0.34046355824711094, 'batch_size': 32}. Best is trial 40 with value: 1.0.
[I 2025-05-21 23:48:34,201] Trial 49 finished with value: 0.8333333134651184 and parameters: {'learning_rate': 0.0017108203386057095, 'filters1': 128, 'filters2': 192, 'filters3': 384, 'kernel_size': 5, 'dense1_units': 64, 'dense2_units': 64, 'dropout1': 0.24597566822289388, 'dropout2': 0.46223064660641877, 'batch_size': 64}. Best is trial 40 with value: 1.0.
Лучшие параметры, найденные Optuna:
learning_rate: 0.0001031548076602442
filters1: 32
filters2: 256
filters3: 384
kernel_size: 3
dense1_units: 64
dense2_units: 128
dropout1: 0.47647451076789765
dropout2: 0.13307339797123377
batch_size: 64
Epoch 1/100
1/1 [==============================] - 3s 3s/step - loss: 0.7781 - accuracy: 0.4038 - auc_50: 0.3141 - val_loss: 0.6832 - val_accuracy: 0.8333 - val_auc_50: 0.9444
Epoch 2/100
1/1 [==============================] - 0s 34ms/step - loss: 0.6990 - accuracy: 0.5962 - auc_50: 0.6508 - val_loss: 0.6803 - val_accuracy: 0.9167 - val_auc_50: 0.9630
Epoch 3/100
1/1 [==============================] - 0s 35ms/step - loss: 0.5278 - accuracy: 0.7692 - auc_50: 0.8852 - val_loss: 0.6776 - val_accuracy: 0.9167 - val_auc_50: 0.9630
Epoch 4/100
1/1 [==============================] - 0s 32ms/step - loss: 0.4964 - accuracy: 0.8077 - auc_50: 0.9062 - val_loss: 0.6759 - val_accuracy: 0.9167 - val_auc_50: 0.9630
Epoch 5/100
1/1 [==============================] - 0s 30ms/step - loss: 0.3923 - accuracy: 0.8654 - auc_50: 0.9562 - val_loss: 0.6741 - val_accuracy: 0.9167 - val_auc_50: 0.9630
Epoch 6/100
1/1 [==============================] - 0s 37ms/step - loss: 0.3690 - accuracy: 0.8654 - auc_50: 0.9656 - val_loss: 0.6723 - val_accuracy: 0.9167 - val_auc_50: 0.9444
Epoch 7/100
1/1 [==============================] - 0s 31ms/step - loss: 0.3070 - accuracy: 0.9038 - auc_50: 0.9867 - val_loss: 0.6717 - val_accuracy: 0.9167 - val_auc_50: 0.9444
Epoch 8/100
1/1 [==============================] - 0s 33ms/step - loss: 0.2419 - accuracy: 0.9038 - auc_50: 0.9867 - val_loss: 0.6714 - val_accuracy: 0.9167 - val_auc_50: 0.9444
Epoch 9/100
1/1 [==============================] - 0s 33ms/step - loss: 0.2765 - accuracy: 0.9231 - auc_50: 0.9641 - val_loss: 0.6711 - val_accuracy: 0.8333 - val_auc_50: 0.9444
Epoch 10/100
1/1 [==============================] - 0s 32ms/step - loss: 0.2544 - accuracy: 0.9231 - auc_50: 0.9844 - val_loss: 0.6704 - val_accuracy: 0.8333 - val_auc_50: 0.9259
Epoch 11/100
1/1 [==============================] - 0s 32ms/step - loss: 0.2489 - accuracy: 0.8846 - auc_50: 0.9719 - val_loss: 0.6695 - val_accuracy: 0.8333 - val_auc_50: 0.9259
Epoch 12/100
1/1 [==============================] - 0s 36ms/step - loss: 0.2067 - accuracy: 0.9231 - auc_50: 0.9797 - val_loss: 0.6684 - val_accuracy: 0.8333 - val_auc_50: 0.8889

Результаты модели с оптимизацией Optuna:
              precision    recall  f1-score   support

           0       1.00      0.56      0.71         9
           1       0.64      1.00      0.78         7

    accuracy                           0.75        16
   macro avg       0.82      0.78      0.75        16
weighted avg       0.84      0.75      0.74        16

Использование памяти: текущее = 21.07MB; пиковое = 41.93MB

Process finished with exit code 0