{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.536650Z",
     "start_time": "2024-11-12T14:44:14.529647Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.568056Z",
     "start_time": "2024-11-12T14:44:14.540651Z"
    }
   },
   "source": [
    "log_data = []\n",
    "log_directory = './processes_logs'\n",
    "for filename in os.listdir(log_directory):\n",
    "    if filename.endswith('.json'):  # Проверяем, что файл имеет расширение .json\n",
    "        file_path = os.path.join(log_directory, filename)  # Полный путь к файлу\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)  # Загружаем данные из JSON-файла\n",
    "                # Проверяем структуру JSON\n",
    "                if (\n",
    "                    isinstance(data, dict) and \n",
    "                    'is_working_mode' in data and \n",
    "                    'timestamp' in data and \n",
    "                    'processes' in data and \n",
    "                    isinstance(data['processes'], list)\n",
    "                ):\n",
    "                    log_data.append(data)  # Добавляем данные в список\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            print(f\"Ошибка при обработке файла {filename}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.598668Z",
     "start_time": "2024-11-12T14:44:14.583863Z"
    }
   },
   "source": [
    "# Подготовка данных\n",
    "processes = []\n",
    "labels = []\n",
    "\n",
    "for entry in log_data:\n",
    "    processes.append(' '.join(entry[\"processes\"]))\n",
    "    entry_is_work_mode = entry[\"is_working_mode\"]\n",
    "    labels.append(entry_is_work_mode)"
   ],
   "outputs": [],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.630846Z",
     "start_time": "2024-11-12T14:44:14.615730Z"
    }
   },
   "source": [
    "# Кодируем метки (True/False) в числа (1/0)\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)"
   ],
   "outputs": [],
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.661859Z",
     "start_time": "2024-11-12T14:44:14.647855Z"
    }
   },
   "source": [
    "# Преобразование строк в числовые векторы\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(processes)\n",
    "sequences = tokenizer.texts_to_sequences(processes)\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(sequences)"
   ],
   "outputs": [],
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.692107Z",
     "start_time": "2024-11-12T14:44:14.677654Z"
    }
   },
   "source": [
    "# Разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.722932Z",
     "start_time": "2024-11-12T14:44:14.709929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Нормализация входных данных X\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# X = X_scaled"
   ],
   "outputs": [],
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.798813Z",
     "start_time": "2024-11-12T14:44:14.739009Z"
    }
   },
   "source": [
    "model = None\n",
    "try:\n",
    "    model = load_model('./predict_processes.h5')\n",
    "except: \n",
    "    print(\"Saved model not found\")\n",
    "if not model:\n",
    "    # Создание модели\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='sigmoid', input_dim=X_train.shape[1]))  # Входной слой\n",
    "    model.add(Dense(32, activation='sigmoid'))  # Скрытый слой\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Выходной слой\n",
    "    # Компиляция модели\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Обучение модели\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=1)\n",
    "    model.save('./predict_processes.h5')"
   ],
   "outputs": [],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.954622Z",
     "start_time": "2024-11-12T14:44:14.814845Z"
    }
   },
   "source": [
    "# Оценка модели\n",
    "y_test = np.where(y_test == 1, 0, 1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1]\n",
      "[1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0]\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8628 - accuracy: 0.6500\n",
      "Accuracy: 65.00%\n"
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:14.986629Z",
     "start_time": "2024-11-12T14:44:14.972626Z"
    }
   },
   "source": [
    "# Прогнозирование\n",
    "def predict_is_work_mode(procs):\n",
    "    seq = tokenizer.texts_to_sequences([procs])\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=X_train.shape[1])\n",
    "    prediction = model.predict(padded)\n",
    "    return prediction[0][0] > 0.5  # И возвращаем True/False"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T14:44:15.018637Z",
     "start_time": "2024-11-12T14:44:15.003634Z"
    }
   },
   "source": [
    "# Пример использования\n",
    "# test_processes = [\"proc1 proc2\"]\n",
    "# print(f'Is Work Mode: {predict_is_work_mode(test_processes)}')"
   ],
   "outputs": [],
   "execution_count": 193
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
