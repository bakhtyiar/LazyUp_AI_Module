Начало оптимизации гиперпараметров с Optuna...
[I 2025-05-24 18:42:54,606] A new study created in memory with name: cnn_optimization
2025-05-24 18:42:54.609450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-24 18:42:54.610159: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
[I 2025-05-24 18:42:56,654] Trial 0 finished with value: 0.0833333432674408 and parameters: {'batch_size': 80, 'epochs': 10, 'n_conv_layers': 2, 'optimizer': 'sgd', 'learning_rate': 1.0797042754892915e-05, 'momentum': 0.1979316624374762, 'filters_layer_0': 192, 'kernel_size_layer_0': 4, 'activation_layer_0': 'relu', 'pool_size_layer_0': 2, 'filters_layer_1': 96, 'kernel_size_layer_1': 3, 'activation_layer_1': 'relu', 'global_pooling': 'avg', 'n_dense_layers': 3, 'dense_units_0': 256, 'dense_activation_0': 'relu', 'dropout_0': 0.36731103944743804, 'dense_units_1': 128, 'dense_activation_1': 'selu', 'dropout_1': 0.49637055748974135, 'dense_units_2': 64, 'dense_activation_2': 'selu', 'dropout_2': 0.23140320132950928, 'patience': 6}. Best is trial 0 with value: 0.0833333432674408.
[I 2025-05-24 18:42:58,937] Trial 1 finished with value: 0.8571428656578064 and parameters: {'batch_size': 112, 'epochs': 17, 'n_conv_layers': 2, 'optimizer': 'sgd', 'learning_rate': 0.0006488849812646601, 'momentum': 0.2550428023982381, 'filters_layer_0': 192, 'kernel_size_layer_0': 4, 'activation_layer_0': 'relu', 'pool_size_layer_0': 2, 'filters_layer_1': 192, 'kernel_size_layer_1': 4, 'activation_layer_1': 'elu', 'global_pooling': 'max', 'n_dense_layers': 3, 'dense_units_0': 160, 'dense_activation_0': 'relu', 'dropout_0': 0.16302412989456375, 'dense_units_1': 256, 'dense_activation_1': 'elu', 'dropout_1': 0.48503191211824903, 'dense_units_2': 192, 'dense_activation_2': 'selu', 'dropout_2': 0.4907125082778745, 'patience': 9}. Best is trial 1 with value: 0.8571428656578064.
[I 2025-05-24 18:43:00,664] Trial 2 finished with value: 1.0 and parameters: {'batch_size': 96, 'epochs': 11, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.007493320880885453, 'filters_layer_0': 64, 'kernel_size_layer_0': 2, 'activation_layer_0': 'relu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 64, 'dense_activation_0': 'relu', 'dropout_0': 0.23939974553930077, 'patience': 5}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:02,277] Trial 3 finished with value: 0.1428571492433548 and parameters: {'batch_size': 64, 'epochs': 17, 'n_conv_layers': 2, 'optimizer': 'sgd', 'learning_rate': 1.5808440299497954e-05, 'momentum': 0.41772284657641023, 'filters_layer_0': 32, 'kernel_size_layer_0': 2, 'activation_layer_0': 'selu', 'pool_size_layer_0': 3, 'filters_layer_1': 160, 'kernel_size_layer_1': 5, 'activation_layer_1': 'relu', 'global_pooling': 'max', 'n_dense_layers': 2, 'dense_units_0': 96, 'dense_activation_0': 'relu', 'dropout_0': 0.221029228269565, 'dense_units_1': 96, 'dense_activation_1': 'relu', 'dropout_1': 0.13785106069743264, 'patience': 5}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:04,469] Trial 4 finished with value: 0.9523809552192688 and parameters: {'batch_size': 128, 'epochs': 12, 'n_conv_layers': 3, 'optimizer': 'adam', 'learning_rate': 0.0007009572426510536, 'filters_layer_0': 96, 'kernel_size_layer_0': 2, 'activation_layer_0': 'selu', 'pool_size_layer_0': 2, 'filters_layer_1': 64, 'kernel_size_layer_1': 5, 'activation_layer_1': 'relu', 'pool_size_layer_1': 2, 'filters_layer_2': 160, 'kernel_size_layer_2': 2, 'activation_layer_2': 'selu', 'global_pooling': 'avg', 'n_dense_layers': 3, 'dense_units_0': 64, 'dense_activation_0': 'elu', 'dropout_0': 0.41741772563106505, 'dense_units_1': 160, 'dense_activation_1': 'selu', 'dropout_1': 0.1236301159195218, 'dense_units_2': 192, 'dense_activation_2': 'elu', 'dropout_2': 0.3058659416218179, 'patience': 5}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:07,520] Trial 5 finished with value: 0.8452380895614624 and parameters: {'batch_size': 96, 'epochs': 21, 'n_conv_layers': 4, 'optimizer': 'rmsprop', 'learning_rate': 0.00010750438205012756, 'filters_layer_0': 224, 'kernel_size_layer_0': 2, 'activation_layer_0': 'relu', 'pool_size_layer_0': 2, 'filters_layer_1': 32, 'kernel_size_layer_1': 4, 'activation_layer_1': 'selu', 'pool_size_layer_1': 3, 'filters_layer_2': 256, 'kernel_size_layer_2': 3, 'activation_layer_2': 'relu', 'pool_size_layer_2': 3, 'filters_layer_3': 64, 'kernel_size_layer_3': 3, 'activation_layer_3': 'selu', 'global_pooling': 'max', 'n_dense_layers': 3, 'dense_units_0': 160, 'dense_activation_0': 'selu', 'dropout_0': 0.3620796944163317, 'dense_units_1': 32, 'dense_activation_1': 'relu', 'dropout_1': 0.22599302360476484, 'dense_units_2': 224, 'dense_activation_2': 'relu', 'dropout_2': 0.16600183139393598, 'patience': 6}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:09,224] Trial 6 finished with value: 0.02380952797830105 and parameters: {'batch_size': 32, 'epochs': 19, 'n_conv_layers': 2, 'optimizer': 'sgd', 'learning_rate': 0.00038818150631835256, 'momentum': 0.2909982478723305, 'filters_layer_0': 128, 'kernel_size_layer_0': 3, 'activation_layer_0': 'selu', 'pool_size_layer_0': 3, 'filters_layer_1': 128, 'kernel_size_layer_1': 2, 'activation_layer_1': 'elu', 'global_pooling': 'avg', 'n_dense_layers': 2, 'dense_units_0': 224, 'dense_activation_0': 'relu', 'dropout_0': 0.19058866579962652, 'dense_units_1': 96, 'dense_activation_1': 'relu', 'dropout_1': 0.35547138727694316, 'patience': 6}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:11,098] Trial 7 finished with value: 0.7380952835083008 and parameters: {'batch_size': 80, 'epochs': 13, 'n_conv_layers': 1, 'optimizer': 'adam', 'learning_rate': 1.948977725573859e-05, 'filters_layer_0': 96, 'kernel_size_layer_0': 5, 'activation_layer_0': 'selu', 'global_pooling': 'avg', 'n_dense_layers': 3, 'dense_units_0': 192, 'dense_activation_0': 'relu', 'dropout_0': 0.43722970269100503, 'dense_units_1': 128, 'dense_activation_1': 'relu', 'dropout_1': 0.11997764337468048, 'dense_units_2': 160, 'dense_activation_2': 'selu', 'dropout_2': 0.4834020459629135, 'patience': 10}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:12,764] Trial 8 finished with value: 0.9523809552192688 and parameters: {'batch_size': 96, 'epochs': 16, 'n_conv_layers': 2, 'optimizer': 'adam', 'learning_rate': 0.0006574594066169449, 'filters_layer_0': 192, 'kernel_size_layer_0': 4, 'activation_layer_0': 'selu', 'pool_size_layer_0': 2, 'filters_layer_1': 64, 'kernel_size_layer_1': 5, 'activation_layer_1': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 64, 'dense_activation_0': 'relu', 'dropout_0': 0.38314441062810367, 'patience': 6}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:14,714] Trial 9 finished with value: 0.9523809552192688 and parameters: {'batch_size': 64, 'epochs': 28, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.00013474870238698293, 'filters_layer_0': 224, 'kernel_size_layer_0': 5, 'activation_layer_0': 'elu', 'global_pooling': 'max', 'n_dense_layers': 2, 'dense_units_0': 160, 'dense_activation_0': 'selu', 'dropout_0': 0.39135007088069296, 'dense_units_1': 64, 'dense_activation_1': 'relu', 'dropout_1': 0.4080231076480073, 'patience': 9}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:16,375] Trial 10 finished with value: 1.0 and parameters: {'batch_size': 16, 'epochs': 25, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.009556485531218642, 'filters_layer_0': 32, 'kernel_size_layer_0': 3, 'activation_layer_0': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 32, 'dense_activation_0': 'elu', 'dropout_0': 0.2649958179640848, 'patience': 3}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:17,904] Trial 11 finished with value: 1.0 and parameters: {'batch_size': 16, 'epochs': 25, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.009140506815428657, 'filters_layer_0': 32, 'kernel_size_layer_0': 3, 'activation_layer_0': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 32, 'dense_activation_0': 'elu', 'dropout_0': 0.2699243161235152, 'patience': 3}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:19,674] Trial 12 finished with value: 1.0 and parameters: {'batch_size': 48, 'epochs': 24, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.00981414382385802, 'filters_layer_0': 64, 'kernel_size_layer_0': 3, 'activation_layer_0': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 32, 'dense_activation_0': 'elu', 'dropout_0': 0.28686063424905595, 'patience': 3}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:22,039] Trial 13 finished with value: 1.0 and parameters: {'batch_size': 16, 'epochs': 30, 'n_conv_layers': 3, 'optimizer': 'rmsprop', 'learning_rate': 0.0025270149240400937, 'filters_layer_0': 64, 'kernel_size_layer_0': 2, 'activation_layer_0': 'elu', 'pool_size_layer_0': 3, 'filters_layer_1': 256, 'kernel_size_layer_1': 2, 'activation_layer_1': 'selu', 'pool_size_layer_1': 2, 'filters_layer_2': 32, 'kernel_size_layer_2': 5, 'activation_layer_2': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 96, 'dense_activation_0': 'elu', 'dropout_0': 0.11088288977562488, 'patience': 4}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:23,837] Trial 14 finished with value: 1.0 and parameters: {'batch_size': 48, 'epochs': 24, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.0028081684478593123, 'filters_layer_0': 32, 'kernel_size_layer_0': 3, 'activation_layer_0': 'relu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 96, 'dense_activation_0': 'elu', 'dropout_0': 0.49585168256514744, 'patience': 4}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:26,654] Trial 15 finished with value: 0.9523809552192688 and parameters: {'batch_size': 128, 'epochs': 21, 'n_conv_layers': 4, 'optimizer': 'rmsprop', 'learning_rate': 0.00286572838122455, 'filters_layer_0': 128, 'kernel_size_layer_0': 2, 'activation_layer_0': 'elu', 'pool_size_layer_0': 3, 'filters_layer_1': 256, 'kernel_size_layer_1': 3, 'activation_layer_1': 'selu', 'pool_size_layer_1': 3, 'filters_layer_2': 32, 'kernel_size_layer_2': 5, 'activation_layer_2': 'relu', 'pool_size_layer_2': 2, 'filters_layer_3': 224, 'kernel_size_layer_3': 5, 'activation_layer_3': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 32, 'dense_activation_0': 'selu', 'dropout_0': 0.24702624221774785, 'patience': 4}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:28,581] Trial 16 finished with value: 1.0 and parameters: {'batch_size': 96, 'epochs': 27, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.005005288180778575, 'filters_layer_0': 64, 'kernel_size_layer_0': 3, 'activation_layer_0': 'relu', 'global_pooling': 'max', 'n_dense_layers': 2, 'dense_units_0': 64, 'dense_activation_0': 'elu', 'dropout_0': 0.3101609847253825, 'dense_units_1': 256, 'dense_activation_1': 'elu', 'dropout_1': 0.24247160950870897, 'patience': 8}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:31,163] Trial 17 finished with value: 1.0 and parameters: {'batch_size': 32, 'epochs': 14, 'n_conv_layers': 3, 'optimizer': 'rmsprop', 'learning_rate': 0.0014174704450127622, 'filters_layer_0': 96, 'kernel_size_layer_0': 2, 'activation_layer_0': 'relu', 'pool_size_layer_0': 3, 'filters_layer_1': 192, 'kernel_size_layer_1': 3, 'activation_layer_1': 'elu', 'pool_size_layer_1': 3, 'filters_layer_2': 224, 'kernel_size_layer_2': 2, 'activation_layer_2': 'elu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 128, 'dense_activation_0': 'relu', 'dropout_0': 0.31879469273094935, 'patience': 3}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:32,889] Trial 18 finished with value: 1.0 and parameters: {'batch_size': 112, 'epochs': 10, 'n_conv_layers': 1, 'optimizer': 'rmsprop', 'learning_rate': 0.0059493687272136695, 'filters_layer_0': 64, 'kernel_size_layer_0': 3, 'activation_layer_0': 'elu', 'global_pooling': 'avg', 'n_dense_layers': 2, 'dense_units_0': 128, 'dense_activation_0': 'elu', 'dropout_0': 0.13988475280013635, 'dense_units_1': 192, 'dense_activation_1': 'elu', 'dropout_1': 0.30306493346200003, 'patience': 7}. Best is trial 2 with value: 1.0.
[I 2025-05-24 18:43:34,784] Trial 19 finished with value: 0.9523810148239136 and parameters: {'batch_size': 48, 'epochs': 22, 'n_conv_layers': 2, 'optimizer': 'adam', 'learning_rate': 0.001430664919904227, 'filters_layer_0': 32, 'kernel_size_layer_0': 4, 'activation_layer_0': 'relu', 'pool_size_layer_0': 2, 'filters_layer_1': 224, 'kernel_size_layer_1': 4, 'activation_layer_1': 'selu', 'global_pooling': 'max', 'n_dense_layers': 1, 'dense_units_0': 64, 'dense_activation_0': 'selu', 'dropout_0': 0.1998808736945609, 'patience': 5}. Best is trial 2 with value: 1.0.
Лучшие гиперпараметры:
    batch_size: 96
    epochs: 11
    n_conv_layers: 1
    optimizer: rmsprop
    learning_rate: 0.007493320880885453
    filters_layer_0: 64
    kernel_size_layer_0: 2
    activation_layer_0: relu
    global_pooling: max
    n_dense_layers: 1
    dense_units_0: 64
    dense_activation_0: relu
    dropout_0: 0.23939974553930077
    patience: 5

Обучение модели с оптимальными гиперпараметрами...
Epoch 1/11
1/1 [==============================] - 2s 2s/step - loss: 3.3298 - accuracy: 0.4510 - auc_20: 0.2795 - val_loss: 0.5224 - val_accuracy: 0.8462 - val_auc_20: 0.9524
Epoch 2/11
1/1 [==============================] - 0s 27ms/step - loss: 0.1537 - accuracy: 0.9412 - auc_20: 0.9845 - val_loss: 0.3505 - val_accuracy: 0.9231 - val_auc_20: 1.0000
Epoch 3/11
1/1 [==============================] - 0s 25ms/step - loss: 0.3762 - accuracy: 0.8627 - auc_20: 0.9720 - val_loss: 0.6856 - val_accuracy: 0.6154 - val_auc_20: 0.8571
Epoch 4/11
1/1 [==============================] - 0s 26ms/step - loss: 0.4975 - accuracy: 0.8824 - auc_20: 0.9495 - val_loss: 0.3958 - val_accuracy: 0.8462 - val_auc_20: 0.9524
Epoch 5/11
1/1 [==============================] - 0s 25ms/step - loss: 0.2423 - accuracy: 0.8824 - auc_20: 0.9837 - val_loss: 0.4654 - val_accuracy: 0.8462 - val_auc_20: 0.9524
Epoch 6/11
1/1 [==============================] - 0s 26ms/step - loss: 0.1481 - accuracy: 0.9020 - auc_20: 0.9876 - val_loss: 0.4625 - val_accuracy: 0.8462 - val_auc_20: 0.9524
Epoch 7/11
1/1 [==============================] - 0s 54ms/step - loss: 0.1797 - accuracy: 0.8824 - auc_20: 0.9783 - val_loss: 0.4261 - val_accuracy: 0.9231 - val_auc_20: 0.9762

Оценка качества на тестовых данных:
1/1 [==============================] - 0s 297ms/step
              precision    recall  f1-score   support

           0       1.00      0.70      0.82        10
           1       0.67      1.00      0.80         6

    accuracy                           0.81        16
   macro avg       0.83      0.85      0.81        16
weighted avg       0.88      0.81      0.81        16

Лучшее значение AUC: 1.0000
Время обучения: 2.91 с
Max RAM Usage: 7.30 MB
Inference time: 0.3415 s

Process finished with exit code 0
